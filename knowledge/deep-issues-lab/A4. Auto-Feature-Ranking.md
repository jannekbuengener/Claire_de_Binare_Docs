---
id: CDB-DR-A4
title: 'Auto-Feature-Ranking (KI-Light)'
subtitle: 'Methoden zur automatisierten Erklärung und Gewichtung von Handelssignalen'
author: 'Jannek Buengener, ChatGPT, Claude Code, und Gemini'
date: '2025-12-17'
status: 'Refactored'
tags:
  - Feature Ranking
  - XAI
  - SHAP
  - Permutation Importance
  - Signalverarbeitung
---

# Auto-Feature-Ranking (KI-Light)

> **Management Summary**
>
> Im Trading bilden **Features** (Merkmale wie technische Indikatoren oder Preisdaten) die Basis für Handelssignale. **Auto-Feature-Ranking** zielt darauf ab, diese Features automatisiert nach ihrer Wichtigkeit zu sortieren, um eine **gewichtete Rangfolge** der einflussreichsten Merkmale zu erzeugen.
>
> Dieses Dokument analysiert "KI-Light"-Methoden – leichtgewichtige, aber leistungsstarke Algorithmen aus dem Bereich der erklärbaren KI (XAI) –, um Transparenz in die Signalentstehung zu bringen. Es werden vier zentrale Ansätze beleuchtet: **SHAP**, **Permutation Importance**, **Recursive Feature Elimination (RFE)** und **Mutual Information**. Ziel ist es, ein technisches Konzept für die Integration eines `cdb_feature_ranker`-Microservice in die bestehende Architektur von *Claire de Binare* zu definieren.

---

## 1. Erklärbare Feature-Ranking-Algorithmen

Im Trading-Umfeld müssen Ranking-Methoden nicht nur zuverlässig, sondern auch **erklärbar** und **performant** sein. Vier Ansätze stehen im Fokus:

### 1.1. SHAP (SHapley Additive exPlanations)

-   **Funktionsweise:** Ein modellagnostisches Verfahren, das jedem Feature fair einen "Shapley-Wert" zuordnet, der seinen Beitrag zur Modellvorhersage quantifiziert.[^1]
-   **Stärken:**
    -   Liefert sowohl **lokale Erklärungen** (für eine einzelne Vorhersage) als auch **globale Wichtigkeiten**.
    -   Für baumbasierte Modelle (z.B. LightGBM) mit `TreeSHAP` sehr performant.[^4]
    -   Hohe Akzeptanz in der XAI-Community aufgrund theoretischer Fundierung.
-   **Anwendung im Trading:** Kann exakt aufzeigen, welche Indikatoren ein spezifisches Handelssignal ausgelöst haben.[^3]

### 1.2. Permutation Importance

-   **Funktionsweise:** Ein globales, modellagnostisches Verfahren, das die Wichtigkeit eines Features misst, indem es dessen Werte im Testdatensatz zufällig permutiert (durchmischt) und die daraus resultierende Verschlechterung der Modellgüte misst.[^5]
-   **Stärken:**
    -   Intuitiv verständlich: Die Wichtigkeit entspricht dem "Schaden", den das Feature anrichtet, wenn es "ausfällt".
    -   Funktioniert mit jedem trainierten Modell.[^6]
-   **Anwendung im Trading:** Hilft zu identifizieren, welche Indikatoren ohne Performance-Verlust aus einem Modell entfernt werden können.

### 1.3. RFE (Recursive Feature Elimination)

-   **Funktionsweise:** Ein Wrapper-Verfahren, das iterativ ein Modell trainiert und das jeweils unwichtigste Feature entfernt, bis die gewünschte Anzahl an Features erreicht ist. Die Reihenfolge der Entfernung ergibt das Ranking.[^8]
-   **Stärken:**
    -   Berücksichtigt **Wechselwirkungen** zwischen Features, da es das Gesamtsystem in jedem Schritt bewertet.
-   **Schwächen:**
    -   Rechnerisch sehr teuer, da das Modell potenziell sehr oft neu trainiert werden muss.

### 1.4. Mutual Information (Gegenseitige Information)

-   **Funktionsweise:** Ein filterbasiertes, modellunabhängiges Verfahren, das misst, wie viel **informationeller Gewinn** ein Feature über die Zielvariable (z.B. die Kursrichtung) liefert.[^10]
-   **Stärken:**
    -   Sehr schnell und effizient in der Berechnung.
    -   Erfasst auch **nichtlineare Zusammenhänge**.
-   **Schwächen:**
    -   Betrachtet Features meist isoliert und ignoriert Interaktionen.

### 1.5. Vergleich und Empfehlung

| Methode | Typ | Geschwindigkeit | Erklärbarkeit | Komplexität |
| :--- | :--- | :--- | :--- |:--- |
| **SHAP** | Modellagnostisch | Schnell (für Bäume) | Sehr hoch (lokal & global) | Hoch |
| **Permutation** | Modellagnostisch | Mittel | Hoch (global) | Gering |
| **RFE** | Wrapper | Langsam | Mittel (nur Ranking) | Mittel |
| **Mutual Info** | Filter | Sehr schnell | Gering (nur Stärke) | Gering |

**Empfehlung:** Für eine "KI-Light"-Implementierung bietet sich eine Kombination an:
1.  **Mutual Information** als schneller Vorfilter zur Reduktion der Dimensionalität.
2.  **SHAP** (mit `TreeSHAP` auf einem LightGBM-Modell) für detaillierte lokale und globale Erklärungen im Echtzeitbetrieb.

---

## 2. Standardisierung durch Feature-Metadaten

Um die Ergebnisse des Rankings nutzbar zu machen, wird ein **standardisiertes, maschinenlesbares Datenblatt** für jedes Feature empfohlen.

**Beispiel-Schema (JSON):**
```json
{
  "feature_name": "RSI_14",
  "beschreibung": "Relative Strength Index, 14-Tage basierend auf Schlusskurs.",
  "gewichtung": 0.08,
  "gewichtung_metrik": "Durchschnittlicher SHAP-Beitrag",
  "gueltigkeit": { "aktiv": true, "seit": "2025-09-01" },
  "quelle": "Berechnet aus OHLCV-Marktdaten",
  "last_updated": "2025-12-01T05:00:00Z"
}
```
Diese Metadaten sollten in einer zentralen Datenbank (z.B. PostgreSQL) oder als Konfigurationsdateien im Repository verwaltet werden, um eine "Single Source of Truth" zu schaffen.

---

## 3. Integration in die CDB-Architektur

Die Einbindung erfolgt als neuer, entkoppelter Microservice (`cdb_feature_ranker`), der sich nahtlos in den bestehenden Event-Flow einfügt.

**Event-Flow:**
1.  Die **Signal Engine** publiziert ein Signal-Event (inkl. der verwendeten Feature-Werte) auf dem Redis-Channel `signals`.
2.  Der neue Service **`cdb_feature_ranker`** abonniert `signals`, empfängt das Event und berechnet in Echtzeit die Feature-Wichtigkeiten (z.B. via SHAP).
3.  Der `cdb_feature_ranker` publiziert ein angereichertes Event (`ranked_features`) auf einem neuen Redis-Channel. Dieses Event enthält die Signal-ID und eine sortierte Liste der Features mit ihren Wichtigkeits-Scores.
4.  Der **Risk Manager** abonniert `ranked_features` und nutzt die zusätzlichen Informationen für erweiterte Validierungsregeln:
    -   **Diversifikations-Check:** Gibt es eine zu starke Abhängigkeit von einem einzelnen Feature?
    -   **Qualitäts-Check:** Gehört ein bekanntermaßen unzuverlässiges Feature zu den Top-Treibern des Signals?
    -   **Transparenz & Logging:** Die Feature-Wichtigkeiten werden mitprotokolliert, um jede Entscheidung nachvollziehbar zu machen.

Diese Architektur erhält die lose Kopplung des Systems, da die Kommunikation weiterhin asynchron über den Redis-Message-Bus erfolgt.[^16]

---

## 4. Handlungsempfehlungen

1.  **Modularität & Testbarkeit:** Entwicklung des `cdb_feature_ranker`-Service als eigenständiges Modul mit umfassenden Unit- und Integrationstests.
2.  **KI-Light-Ansatz:** Start mit einer leichtgewichtigen und schnellen Methode, z.B. **SHAP auf einem LightGBM-Modell**, um den Latenz-Overhead minimal zu halten.
3.  **Persistenz:** Die erzeugten Feature-Rankings sollten persistent gespeichert werden (z.B. in PostgreSQL durch den `db_writer`), um historische Analysen zu ermöglichen.
4.  **Schrittweise Aktivierung:** Zunächst im **Paper-Trading** oder Shadow-Mode testen. Die Ranking-Informationen anfangs nur protokollieren und erst nach erfolgreicher Validierung für aktive Risikoentscheidungen nutzen.
5.  **Kontinuierliches Monitoring:** Die Performance und Latenz des Ranking-Prozesses sowie die Stabilität der Feature-Wichtigkeiten über die Zeit überwachen.

Durch die Integration von erklärbarer KI wird die Transparenz und Vertrauenswürdigkeit des Handelssystems signifikant erhöht und eine datengestützte Grundlage für die kontinuierliche Verbesserung der Strategien geschaffen.

---

