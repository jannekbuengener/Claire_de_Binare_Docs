---
status: archived
migration_status: resolved
note: "Legacy file-links entfernt, Textreferenzen beibehalten (ADR-027)"
---

## cdb\_redis

FÃ¼r einen Neuaufbau des **Claire de Binare** Servers wird zunÃ¤chst eine geeignete Systemumgebung benÃ¶tigt. Idealerweise steht ein **aktueller x64-Server oder Rechner** zur VerfÃ¼gung (getestet wurde z.â€¯B. auf Docker Desktop unter Windows) mit installiertem **Docker** und **Docker-Compose**[\[1\]]. Dadurch sind Anforderungen an das Basis-Betriebssystem gering â€“ Linux oder Windows mit Docker-UnterstÃ¼tzung reichen aus. FÃ¼r den Betrieb sollten ca. 1â€“2â€¯GB RAM und eine stabile Internetverbindung eingeplant werden, da Marktdaten in Echtzeit von der **MEXC**\-API bezogen werden.

**Software/Services:** BenÃ¶tigt werden Container-Images fÃ¼r **Redis** (Message-Bus) und **PostgreSQL** (Datenbank), sowie die Python-basierten Microservices des Bots selbst (als Docker-Images). Docker-Compose orchestriert diese Komponenten. Beim Neuaufsetzen zieht Docker-Compose die Basis-Images (z.â€¯B. redis:7-alpine und postgres:15-alpine) automatisch aus dem Registry[\[2\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L28-L36)[\[3\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L9-L17).

**Zugriffstokens & Secrets:** In einer konfigurierten **.env**\-Datei sind alle sensiblen Zugangsdaten und Konfigurationswerte abzulegen. Dazu zÃ¤hlen insbesondere:

* **MEXC API Key & Secret:** API-SchlÃ¼ssel fÃ¼r die BÃ¶rse (nur Lese-/Handelsrechte, **keine Withdraw-Rechte** gemÃ¤ÃŸ Sicherheitsrichtlinie[\[4\]]). Diese sind in den Env-Vars MEXC\_API\_KEY und MEXC\_API\_SECRET zu hinterlegen[\[5\]]. Ebenso die Basis-URL der API (MEXC\_BASE, default: MEXC Contract-API).

* **Redis-Zugang:** Ein Redis-Instanz wird als Message-Bus genutzt. In der .env mÃ¼ssen REDIS\_PASSWORD (gemÃ¤ÃŸ Compose erforderlich[\[6\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L13-L19)) und ggf. Host/Port stehen. StandardmÃ¤ÃŸig verbinden die Services auf REDIS\_HOST=redis (Container-Hostname) und Port 6379[\[7\]].

* **PostgreSQL-Zugang:** Die Datenbank-Zugangsdaten POSTGRES\_USER, POSTGRES\_PASSWORD und der Datenbankname POSTGRES\_DB sind anzugeben[\[8\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L32-L40). Im Docker-Setup wird z.â€¯B. ein User *cdb\_user* und die DB *claire\_de\_binare* genutzt (siehe unten).

* **Weitere Secrets:** FÃ¼r Benachrichtigungen via Web-Push sind â€“ falls das Notification-Service genutzt wird â€“ ein VAPID-SchlÃ¼sselpaar (WEBPUSH\_VAPID\_PUBLIC\_KEY, WEBPUSH\_VAPID\_PRIVATE\_KEY) sowie ein Kontakt-URL (WEBPUSH\_CONTACT) erforderlich[\[9\]]. Legacy-Optionen wie Telegram-Bot-Token und Chat-ID kÃ¶nnen entfallen[\[10\]].

**Hardware**: Spezielle Hardware ist nicht erforderlich, da alle Komponenten in Docker-Containern laufen. Eine zuverlÃ¤ssige **SpeicherlÃ¶sung** fÃ¼r Persistenz sollte vorhanden sein (Docker Volumes fÃ¼r Datenbank und ggf. Logs), sowie genug CPU-Ressourcen fÃ¼r die Datenverarbeitung in Echtzeit. Backups (siehe unten **Sicherheit & Recovery**) sollten auf ein separates Medium/Verzeichnis erfolgen.

## 2\. Deployment Stack (Docker, Compose, Python, Redis, PostgreSQL, Flask)

Claire de Binare setzt auf einen **containerisierten Deployment-Stack** zur einheitlichen Bereitstellung aller Komponenten. Kernbestandteile und ihr Zusammenspiel:

* **Docker & Docker-Compose:** Alle Services laufen in Docker-Containern, definiert durch individuelle Dockerfile\-Rezepte und orchestriert Ã¼ber eine zentrale docker-compose.yml. Docker-Compose startet die Infrastruktur (Redis, Postgres, Monitoring) sowie die Bot-Services in korrekter Reihenfolge. Beispielsweise wird in der Compose-Datei der Redis-Container cdb\_redis definiert (mit persistentem Volume fÃ¼r Daten und Passwortschutz)[\[3\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L9-L17), ebenso der PostgreSQL-Container cdb\_postgres mit Initialisierung des DB-Schemas[\[8\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L32-L40). Die Compose-Datei legt zudem fest, welche Ports nach auÃŸen geÃ¶ffnet werden, und nutzt depends\_on, um AbhÃ¤ngigkeiten und Startreihenfolge auszudrÃ¼cken (z.â€¯B. muss Redis laufen, bevor die Signal-Engine startet[\[11\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L178-L186)).

* **Python-Anwendungen & Requirements:** Die fachliche Logik ist in **Python** implementiert (Version 3.11). Jedes Microservice-Modul hat sein eigenes Verzeichnis mit Code und eine requirements.txt fÃ¼r Dependencies. Wichtige Bibliotheken sind u.â€¯a. **Flask** (fÃ¼r HTTP-Endpunkte wie Health-Checks), **redis-py** (fÃ¼r die Pub/Sub-Anbindung), ggf. **ccxt** (fÃ¼r BÃ¶rsen-API-Zugriff in der Execution) sowie ORMs/DB-Treiber wie SQLAlchemy und Psycopg2 fÃ¼r die Datenbankanbindung[\[12\]]. Die requirements.txt der Services listen nur dienstspezifische AbhÃ¤ngigkeiten (z.â€¯B. Flask, redis, dotenv) â€“ dadurch bleiben die Container schlank[\[13\]][\[14\]].

* **Flask Microservices:** Jeder Service ist als eigenstÃ¤ndige Flask-Anwendung gestaltet. Flask stellt minimale HTTP-Endpunkte bereit â€“ vor allem /health fÃ¼r Health-Checks, evtl. /status oder /metrics fÃ¼r Statusabfragen[\[15\]]. Die Flask-App lÃ¤uft innerhalb des Containers auf dem vorgesehenen Port (siehe unten Architektur/Ports) und ermÃ¶glicht so Docker-Compose Healthchecks. Im Dockerfile wird dafÃ¼r der Port exponiert und ein Healthcheck-CMD definiert (z.â€¯B. via curl auf /health)[\[16\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L14-L19)[\[17\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L20-L23). Die Flask-Server starten in den jeweiligen service.py\-Mainprogrammen.

* **Redis (Message-Bus):** Redis dient als zentrales **Pub/Sub-Message-Bus** fÃ¼r die lose gekoppelte Kommunikation zwischen den Microservices. Der Redis-Container wird mit Persistenz (AppendOnly Log) konfiguriert und im Compose-File hinterlegt[\[18\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L16-L24). Alle Services verbinden sich Ã¼ber die in .env konfigurierten Host/Port/Passwort auf diesen Bus. Ereignisse wie Marktdaten, Signale etc. werden als JSON-Nachrichten Ã¼ber definierte Channels (Topics) verÃ¶ffentlicht â€“ Redis verteilt sie an alle abonnierten Dienste (siehe Architekturbeschreibung).

* **PostgreSQL (Persistenz):** Die relationale Datenbank speichert **persistente Daten**: Signale, Trades, Risk-Entscheidungen, Performance-Metriken usw. Beim Initialstart legt der Postgres-Container mittels eingebundenem Schema-SQL-Skript die nÃ¶tigen Tabellen an[\[19\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L38-L44). Der DB-Zugriff erfolgt aus den Services heraus (z.â€¯B. Speichern von Trades nach AusfÃ¼hrung). Wichtig: Vor dem Start mÃ¼ssen die DB-Zugangsdaten in .env stimmen, da die Services diese nutzen, um eine DB-Verbindung aufzubauen. Im Compose ist Postgres durch depends\_on bei der Execution-Komponente berÃ¼cksichtigt (Execution-Service wartet auf DB-Start)[\[20\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L236-L244).

**Docker-Aufbau (Dockerfiles):** Jedes Microservice-Modul hat ein eigenes Dockerfile, meist basierend auf python:3.11-slim. Darin werden die AbhÃ¤ngigkeiten installiert und der Anwendungscode kopiert[\[21\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L9-L16). Es wird ein eingeschrÃ¤nkter **Non-Root-User** erstellt (Security Best Practice: â€least privilegeâ€œ)[\[22\]][\[16\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L14-L19), und der Standard-Startbefehl fÃ¼hrt die Python-Service-Main aus. Beispielhaft zeigt der Dockerfile-Auszug des Risk-Manager-Dienstes die Erstellung eines Users und einen Healthcheck-Befehl:

RUN useradd \-m \-u 1000 riskuser && chown \-R riskuser:riskuser /app    
USER riskuser    
HEALTHCHECK \--interval=30s \--timeout=3s \--retries=3 \\    
    CMD curl \-f http://localhost:8002/health || exit 1    
EXPOSE 8002    
CMD \["python", "-u", "service.py"\]  

*Quelle: Risk-Manager Dockerfile[\[23\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/backoffice/services/risk_manager/Dockerfile#L14-L22).*

**docker-compose.yml:** In der Compose-Datei sind alle Container und deren Konfiguration vermerkt. Zentral ist das **Zusammenspiel der Services**: z.â€¯B. startet der bot\_ws (WebSocket-Datenfeed) Container erst nach Redis[\[24\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L112-L119); die signal\_engine (Signal-Engine) startet nach Redis *und* dem Datenfeed[\[11\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L178-L186); der risk\_manager wartet auf Redis und die Signal-Engine[\[25\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L206-L214); die execution\_service hÃ¤ngt von Redis, Risk-Manager *und* Datenbank ab[\[20\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L236-L244). Diese Staffelung stellt sicher, dass bei einem Neustart jeder Dienst seine benÃ¶tigten Gegenstellen vorfindet. Compose verwaltet auch gemeinsame **Netzwerke** (hier ein Bridge-Netz cdb\_network fÃ¼r internen Traffic[\[26\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L24-L27)[\[27\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L252-L255)) und **Volumes** (fÃ¼r persistente Redis-/Postgres-Daten[\[28\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L16-L19)[\[29\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L36-L40)). Die Ports der Services werden meist 1:1 an den Host gemappt (8000/8001/8002/etc.), wÃ¤hrend interne Verbindungen Ã¼ber den Service-Namen laufen (z.â€¯B. redis:6379).

## 3\. ArchitekturÃ¼berblick (Microservices & Event-Bus)

Claire de Binare folgt einer **Microservice-Architektur** mit entkoppelten, ereignisgesteuerten Komponenten[\[30\]]. GemÃ¤ÃŸ *ARCHITEKTUR.md* sind folgende Haupt-Services definiert:

* **Datenfeed / Ingestion-Service:** Bezieht in Echtzeit Marktdaten von MEXC (WebSocket-Streams fÃ¼r Kurse/Orderbuch, REST fÃ¼r periodische Updates), normalisiert die Daten und publiziert sie als **MarketData-Events** auf dem Message-Bus[\[31\]]. (Im aktuellen Setup entspricht dies dem bot\_ws Container, der z.â€¯B. Top-5 MÃ¤rkte streamt.)

* **Strategie-Engine (Signal-Generator):** Subskribiert die Marktdaten und berechnet kontinuierlich definierte **Indikatoren** (Momentum, Volumen-Spikes, Orderbuch-Imbalance etc.). Sobald die Regeln ein Handelssignal auslÃ¶sen (Kauf/Verkauf inkl. BegrÃ¼ndung), wird ein **Signal-Event** auf dem Bus publiziert[\[32\]]. (Beispiel: Wenn Preis in 15â€¯min \>3% steigt *und* Volumen-Kriterium erfÃ¼llt ist, generiert die Engine ein BUY-Signal[\[33\]][\[34\]].)

* **Risikomanager:** EmpfÃ¤ngt neue Signal-Events als **Safety-Layer** vor jeder AusfÃ¼hrung. Er prÃ¼ft mehrstufig alle vordefinierten Limits â€“ z.â€¯B. maximale PositionsgrÃ¶ÃŸe pro Trade, Gesamt-Exposition aller offenen Trades, Tagesverlust-Limit, Stop-Loss-Grenzen sowie AuffÃ¤lligkeiten im Markt[\[35\]][\[36\]]. Ist das Signal *konform*, publiziert der Risikomanager ein **Order-Event** (Freigabe zur AusfÃ¼hrung) auf dem Bus; Ã¼berschreitet das Signal ein Limit, wird es **blockiert** und stattdessen ein **Alert-Event** (Warnung) erzeugt[\[37\]]. AuÃŸerdem Ã¼berwacht dieser Service globale **Circuit-Breaker**: Bei z.â€¯B. â‰¥5% Tagesverlust stoppt er den Handel komplett und lÃ¶st einen Alarm aus[\[38\]][\[39\]].

* **Execution-Service:** HÃ¶rt auf freigegebene Order-Events und fÃ¼hrt die Trades an der BÃ¶rse aus (Ã¼ber die MEXC-API, z.â€¯B. mittels CCXT-Bibliothek)[\[40\]]. Nach Orderplatzierung verarbeitet der Service das Ergebnis â€“ ob AusfÃ¼hrung (Fill) oder Fehler â€“ und publiziert ein **OrderResult-Event** zurÃ¼ck auf den Bus[\[41\]]. Damit werden alle beteiligten Module informiert (fÃ¼r Trade-Buchung, Risikoupdate, Benachrichtigung). Der Execution-Service kÃ¼mmert sich um robuste DurchfÃ¼hrung: z.â€¯B. Wiederholungsversuche bei Timeouts und Idempotenz (Vermeidung von Doppelorders durch eindeutige client\_id)[\[41\]].

* **Persistenz-Service (Signal-Writer):** Dieser optionale Service (teils auch in die anderen integriert) sorgt fÃ¼r das **Persistieren wichtiger Ereignisse** in der Datenbank. Er kann relevante Events vom Bus abonnieren (Signals, Orders, Trades, Alerts) und schreibt sie in die entsprechenden Tabellen[\[42\]]. So entsteht ein Audit-Log aller AktivitÃ¤ten. In der aktuellen Implementierung werden z.â€¯B. alle generierten Signale, ausgefÃ¼hrten Trades und Risk-Entscheidungen gespeichert (siehe Abschnitt *Datenbank*).

* **Benachrichtigungs-Service:** Wartet auf Alert-Events oder wichtige Trade-Events und versendet **Push-Benachrichtigungen** an den Nutzer[\[43\]]. Kritische Meldungen (z.â€¯B. Not-Stopp ausgelÃ¶st, Order abgelehnt) werden sofort als Push geschickt, weniger dringende Infos nur im Dashboard angezeigt. (Dieser Service ist konzeptionell vorgesehen â€“ derzeit kÃ¶nnen Alerts z.â€¯B. via Web-Push im UI oder logischerweise via Telegram erfolgen, wobei Telegram laut Konzept deprecated ist[\[10\]].)

* **Dashboard / UI-Service:** Stellt eine Web-OberflÃ¤che bereit, um den **Echtzeit-Status** des Bots einzusehen und ggf. Aktionen manuell durchzufÃ¼hren. Das Dashboard (z.â€¯B. Prototyp als Streamlit-App) zeigt offene Positionen, P\&L, letzte Signale/Trades, Risk-Alerts etc. an[\[44\]]. Es abonniert dafÃ¼r die Bus-Events oder fragt periodisch die Datenbank. Zudem bietet das UI Kontrollfunktionen wie einen **â€œNot-Ausâ€**\-Schalter, um alle HandelsaktivitÃ¤ten sofort zu stoppen[\[45\]]. (Im MVP ist das UI optional und kann spÃ¤ter hinzugefÃ¼gt werden.)

Alle diese Services kommunizieren **asynchron Ã¼ber den Message-Bus** (typischerweise Redis Pub/Sub) nach dem **Publish/Subscribe-Muster**[\[30\]]. Dadurch sind sie lose gekoppelt und unabhÃ¤ngig deploybar â€“ ein Dienstausfall legt nicht das Gesamtsystem lahm, sondern Nachrichten stauen sich hÃ¶chstens im Bus und der Dienst kann neu starten, ohne Zustandsverlust[\[46\]].

**Event-getriebene Kommunikation:** Die zentrale Rolle spielt der Redis-Bus mit definierten **Topics** (KanÃ¤len). Die wichtigsten Topics und ihre Publisher/Subscriber sind in der folgenden Tabelle dargestellt (vgl. ARCHITEKTUR.md):

| Topic | Publisher | Subscriber | Inhalt (Kurz) |
| :---- | :---- | :---- | :---- |
| market\_data | Datenfeed-Service | Strategie-Engine, UI | Marktdaten (Preis, Volumen, Symbol, etc.) |
| signals | Strategie-Engine | Risikomanager | Handelssignal (Symbol, Richtung, Konfidenz, Grund) |
| orders | Risikomanager (Freigabe) | Execution-Service | Order-Anforderung (Symbol, Side, Menge, ggf. SL/TP) |
| order\_result | Execution-Service | Risikomanager, UI, Notify, Persistenz | AusfÃ¼hrungsergebnis (Order-ID, Status, Preis, Fills, Fehler) |
| alerts | Risk/Execution/Monitoring | Notify-Service, UI, Persistenz | Alarmmeldung (Level, Code, Nachricht, Kontext) |
| health | *alle Dienste* | Monitoring/UI | Health-Status der Dienste (Name, Status, Zeit) |

*Quelle: Topics gemÃ¤ÃŸ Architektur[\[47\]][\[48\]].*

Diese **Message-Bus-Topologie** (hier auf Redis umgesetzt) ermÃ¶glicht einen entkoppelten, skalierbaren Event-Flow. Jeder Service hÃ¶rt nur auf die fÃ¼r ihn relevanten Events und ignoriert andere. Neue Komponenten (z.â€¯B. ein ML-basiertes Modul) kÃ¶nnen einfach durch Subscriben/Publizieren zusÃ¤tzlicher Topics integriert werden, ohne dass bestehende Komponenten geÃ¤ndert werden mÃ¼ssen.

**Start-Reihenfolge der Dienste:** Beim Neustart des gesamten Systems ist die richtige Sequenz wichtig, damit kein Dienst ins Leere lÃ¤uft. Zuerst mÃ¼ssen die **Infrastruktur-Services** verfÃ¼gbar sein: **Redis** (Pub/Sub-Bus) und die **PostgreSQL-Datenbank**. Erst danach sollten die anwendungsbezogenen Container hochgefahren werden. Praxisgerecht Ã¼bernimmt docker-compose dies via AbhÃ¤ngigkeiten: So startet cdb\_signal (Signal-Engine) erst, wenn Redis lÃ¤uft und der Datenfeed (cdb\_ws) Daten liefert[\[11\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L178-L186). Der Risk-Manager wartet auf die Signal-Engine[\[25\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L206-L214), und der Execution-Service wiederum auf den Risk-Manager *und* die Datenbank[\[20\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L236-L244). Dieses gestaffelte Hochfahren stellt sicher, dass z.â€¯B. die Signal-Engine beim Start direkt auf den Redis-Bus verbinden kann und auch bereits Marktdaten-Events vorfindet, oder dass der Execution-Service eine Datenbankverbindung herstellen kann, weil Postgres bereit ist. Sollte ein Dienst dennoch zu frÃ¼h gestartet sein (etwa Redis VerzÃ¶gerung), besitzen die Services Wiederholungs- bzw. Backoff-Logik, um die Verbindung erneut zu versuchen[\[49\]][\[50\]] (z.â€¯B. reconnect beim WebSocket-Datenfeed). Insgesamt gilt: **Redis und DB zuerst**, dann *Datenfeed â†’ Strategie â†’ Risiko â†’ Execution â†’ optionale UI/Notify*.

## 4\. Datenbank (PostgreSQL Setup & Schema)

FÃ¼r Persistenz und Nachvollziehbarkeit betreibt Claire de Binare eine **PostgreSQL**\-Datenbank. Das SQL-Schema ist in der Datei *DATABASE\_SCHEMA.sql* festgelegt und wird beim Neuaufsetzen automatisch angewendet (durch Mounten der SQL-Datei ins Postgres-Container-Initdir[\[19\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L38-L44)). Wichtig: Vor dem ersten Start mÃ¼ssen die in .env definierten DB-Zugangsdaten stimmen, damit der Container die DB erstellen kann (POSTGRES\_USER, POSTGRES\_PASSWORD, POSTGRES\_DB[\[8\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L32-L40)). Der Datenbankname ist standardmÃ¤ÃŸig **claire\_de\_binare** (ohne Accent)[\[51\]] â€“ dieser muss konsistent verwendet werden.

Nach dem Start enthÃ¤lt die Datenbank das Schema mit allen notwendigen Tabellen und ggf. Basisdaten. Die wichtigsten Tabellen aus *DATABASE\_SCHEMA.sql* sind:

* **signals** â€“ EnthÃ¤lt alle generierten **Trading-Signale** der Strategie-Engine[\[52\]]. Pro Eintrag: fortlaufende ID, Symbol, Side (BUY/SELL), Confidence (Konfidenzwert 0â€“1), Reason (BegrÃ¼ndungstext), Preis zum Signalzeitpunkt, ProzentÃ¤nderung, Volumen sowie Zeitstempel. Indexe bestehen u.a. auf Symbol und Timestamp fÃ¼r schnelle Abfragen.

* **trades** â€“ Beinhaltet ausgefÃ¼hrte **Trades** (Einstiege/Ausstiege)[\[53\]]. VerknÃ¼pft ggf. auf das Signal (signal\_id), enthÃ¤lt Menge, Entry/Exit-Preise, PnL (Profit/Loss absolut und %), Status (OPEN/CLOSED), zugeordnete Order-IDs usw. Hier werden alle abgeschlossenen Trades zu Audit-Zwecken archiviert.

* **risk\_events** â€“ Protokolliert Entscheidungen des **Risikomanagers**[\[54\]]. Zum Beispiel wenn ein Signal geblockt wurde (blocked\_order=true) oder ein Circuit Breaker gegriffen hat. EnthÃ¤lt Feld severity (INFO/WARNING/CRITICAL) und eine Beschreibung des Ereignisses (z.â€¯B. *â€œTagesverlust-Limit Ã¼berschritten â€“ Handel gestopptâ€*).

* **orders** â€“ HÃ¤lt die Historie aller **Order-Anfragen** und deren Status[\[55\]] (PENDING, FILLED, PARTIALLY\_FILLED, CANCELLED, REJECTED). Hier werden auch ggf. Exchange-spezifische IDs, Zeitstempel der Orderaufgabe und AusfÃ¼hrung etc. gespeichert. Damit lÃ¤sst sich jeder Order-Lebenszyklus nachvollziehen.

* **Weitere Tabellen:** positions fÃ¼r aktuell offene Positionen (fÃ¼r die Berechnung der Gesamt-Exposition)[\[56\]], balances fÃ¼r regelmÃ¤ÃŸige Kapital-Snapshots (Equity, Margin, PnL)[\[57\]], health\_checks fÃ¼r periodische Service-Health-Status[\[58\]], metrics fÃ¼r Performance-Metriken[\[59\]] (z.â€¯B. durchschnittliche Signal-Konfidenz, Verarbeitungszeiten) sowie strategy\_params zur Historisierung von Strategie-ParameterÃ¤nderungen[\[60\]].

Beim erstmaligen Aufsetzen werden durch das Schema-Skript auch einige **Initialdaten** eingetragen â€“ z.â€¯B. Standard-Parameter in strategy\_params (Momentum-Schwelle, max. Drawdown etc.)[\[61\]] â€“ sowie Berechtigungen gesetzt. So wird ein DB-Benutzer (z.â€¯B. â€claireâ€œ bzw. der in POSTGRES\_USER gesetzte User) berechtigt, die Tabellen zu selektieren und zu verÃ¤ndern[\[62\]]. AuÃŸerdem wird eine schema\_version Tabelle angelegt, in der die Schema-Version (â€1.0â€œ) vermerkt ist[\[63\]]. FÃ¼r zukÃ¼nftige Ã„nderungen kÃ¶nnten hier Migrationen versioniert werden.

**Migration/Updates:** Sollte das System neu aufgesetzt werden, aber eine bestehende Datenbank mit Ã¤lteren Daten vorhanden sein, ist darauf zu achten, dass das Schema kompatibel ist. Im Zweifel kÃ¶nnen Migrationen erforderlich sein, um alte Tabellenversionen an das neue Schema anzupassen (dies wÃ¼rde Ã¼ber ErhÃ¶hung der schema\_version und separate Migration-Skripts passieren). Im vorliegenden Schema 1.0 sind jedoch alle oben genannten Tabellen frisch anzulegen, ein Neuaufsetzen mit leerer DB ist daher unkompliziert.

**Persistierte Signale & Events:** Alle wichtigen Events des Bots werden in der DB persistiert, um **Transparenz und Auditierbarkeit** zu gewÃ¤hrleisten. Beim Neuaufsetzen auf einem frischen Server sollten vorhandene historische Daten (Signals, Trades etc.) nach MÃ¶glichkeit aus Backups wiederhergestellt werden, um den fortlaufenden Betrieb mit Historie zu ermÃ¶glichen. Andernfalls startet das System mit leeren Tabellen â€“ was funktional kein Problem ist (der Bot kann auch ohne historische Daten handeln), aber man verliert die Bezugswerte fÃ¼r z.â€¯B. Tages-Drawdown-Berechnung, offene Positionen etc. Im Abschnitt *Sicherheit & Recovery* sind Backup/Recovery-Prozesse erlÃ¤utert, um persistierte Events zu sichern. Kurz gesagt: **Vor dem Neuaufsetzen immer ein Backup der DB ziehen**, damit keine Signale/Trades verloren gehen.

## 5\. Event-Handling (Event-Bus & Subscriptions)

Die **ereignisgetriebene Kommunikation** erfolgt Ã¼ber den zentralen **Message-Bus (Redis)**. Alle Services sind darauf ausgelegt, bestimmte Topics zu **subscriben** (abonnierten) und darauf Ereignisse zu **publizieren**, gemÃ¤ÃŸ ihrer Rolle. Die Integration ist im Code typischerweise Ã¼ber die Redis-Pub/Sub-API realisiert (z.â€¯B. via redis-py Library). Jedes Event wird als JSON-Objekt verschickt, oftmals validiert durch ein gemeinsames Schema (siehe EVENT\_SCHEMA.json). Dieses JSON-Schema definiert die erwarteten Felder und Typen pro Event-Typ, was Konsistenz sicherstellt â€“ z.â€¯B. ein Signal-Event muss type \= "signal", ein Symbol, Timestamp, side (BUY/SELL) und confidence 0â€“1 enthalten[\[64\]]. Solche formalen Schemabeschreibungen kÃ¶nnen genutzt werden, um Eingaben frÃ¼h zu prÃ¼fen und Fehlformate abzufangen.

Im laufenden Betrieb fungiert Redis als **verteilter Event-Bus**: Ein Publisher schreibt z.â€¯B. eine neue Nachricht auf Topic "signals" â€“ Redis leitet diese sofort an alle Services weiter, die "signals" abonniert haben. Unten eine Zusammenfassung, welche Services welche Topics bearbeiten (siehe auch Tabelle in Abschnitt 3):

* **Topic market\_data:** Publiziert vom Datenfeed-Service mit den neuesten Marktdaten (z.â€¯B. Preisaktualisierungen). Abonniert von der Strategie-Engine (zur Signalberechnung) und ggf. vom Dashboard (fÃ¼r Charts)[\[65\]].

* **Topic signals:** Publiziert von der Strategie-Engine, sobald ein neues Handelssignal erkannt wurde. Nur der Risikomanager subscribed auf signals, da er als nÃ¤chstes jeden Signal verarbeitet[\[65\]].

* **Topic orders:** Publiziert vom Risikomanager, wenn ein Signal freigegeben wurde (Order-Anforderung). Nur der Execution-Service abonniert orders und fÃ¼hrt diese Order dann aus[\[66\]]. (Nicht freigegebene Signale erzeugen stattdessen einen Alert, siehe dort.)

* **Topic order\_result:** Publiziert vom Execution-Service nach AusfÃ¼hrung einer Order â€“ enthÃ¤lt entweder die BestÃ¤tigung eines Trades oder eine Fehlermeldung[\[67\]]. Abonniert vom Risikomanager (zur Kenntnisnahme des Ergebnisses, z.â€¯B. fÃ¼r PnL-Berechnung oder Fehlermeldung), vom Benachrichtigungs-Service (um z.â€¯B. *Trade ausgefÃ¼hrt* Push zu senden) und vom UI (zur Aktualisierung der OberflÃ¤che)[\[68\]]. Auch ein Persistenz-Service wÃ¼rde hier mitlauschen, um Trades in die DB zu schreiben.

* **Topic alerts:** Publiziert von verschiedenen Stellen, insbesondere dem Risikomanager (wenn er ein Signal blockiert oder einen globalen Stopp auslÃ¶st) oder vom Execution-Service (bei kritischen Fehlern). Abonniert vom Notify-Service und UI, die solche Alerts dem Benutzer anzeigen[\[69\]]. Auch hier kann Persistenz die Alerts loggen.

* **Topic health:** Publiziert von *jedem* Service in regelmÃ¤ÃŸigen AbstÃ¤nden oder auf Anfrage, um den eigenen Gesundheitsstatus zu melden. Abonniert z.â€¯B. vom Dashboard oder einem Monitoring-Service, um den Gesamtzustand aller Dienste zu Ã¼berwachen[\[70\]]. Im Compose-Setup erfolgt Health-Checking allerdings primÃ¤r durch Docker-Mechanismen (siehe Healthcheck in Dockerfile/Compose).

Die Event-Nachrichten selbst sind JSON-Strukturen mit festgelegten Feldern. Ein **Beispiel**: Ein Signal-Event kÃ¶nnte wie folgt aussehen:

{  
  "type": "signal",  
  "symbol": "BTC\_USDT",  
  "timestamp": 1696789260,  
  "side": "BUY",  
  "confidence": 0.85,  
  "reason": "Momentum-Kaufsignal (+5%/15min, hohes Volumen)"  
}

Hier signalisiert die Strategie-Engine einen Kaufsignal fÃ¼r BTC/USDT mit 85% Confidence und nennt als Grund den Momentum-Anstieg. Der Risikomanager wÃ¼rde dieses Event aus dem Redis-Stream lesen und entsprechend reagieren. Ã„hnlich standardisiert sind Order-Events (type: "order" mit Symbol, side, quantity, etc.), OrderResult-Events (status: FILLED/ERROR usw.) und Alerts (level: INFO/WARNING/CRITICAL mit Code und Message)[\[71\]].

**Implementierungsdetails:** In jedem Service lÃ¤dt die Konfigurationsroutine die relevanten Bus-Parameter aus den Environment-Variablen (z.â€¯B. REDIS\_HOST, REDIS\_PORT, REDIS\_PASSWORD) â€“ im Standard sind Host "redis" und Port 6379 gesetzt[\[7\]], Passwort muss aus .env kommen. Die Services stellen beim Start die Verbindung zu Redis her. Gelingt das nicht (Redis noch nicht bereit), wird meist in Intervallen ein Retry unternommen, wie oben erwÃ¤hnt. Sobald verbunden, fÃ¼hren die Services ein **Subscribe** auf ihre Topics durch (bspw. Strategie abonniert market\_data, Risk abonniert signals usw.) und lauschen in separaten Threads oder Async-Callbacks auf neue Events. Beim Eintreffen eines Events wird dieses deserialisiert (JSON \-\> Objekt) und der jeweilige **Event-Handler** im Service greift die Daten auf (z.â€¯B. Risiko prÃ¼ft Limits bei Signal, Execution fÃ¼hrt Order bei Order-Event aus). Publizieren wiederum erfolgt nach Bearbeitung analog: der Service serialisiert das Event-Objekt zu JSON und pusht es auf den Redis-Kanal.

Durch diese Architektur sind die Services entkoppelt: Die Kommunikation ist **asynchron** und erfolgt in **Echtzeit**. Sollte ein Service ausfallen, puffert Redis die Nachrichten nicht (Pub/Sub verteilt nur live), aber dank der kurzen Abfolgen (Marktdaten alle Sekunde, Signale alle paar Minuten) ist ein Wiederverbinden unproblematisch â€“ verpasste Events sind entweder nicht kritisch oder kÃ¶nnen durch erneute Marktdaten schnell nachgeliefert werden. FÃ¼r wichtige Events kÃ¶nnte man Redis Streams oder eine Message-Queue mit Persistenz einsetzen (in Zukunft evtl. NATS, RabbitMQ, Kafka), aber im aktuellen Setup genÃ¼gt der Redis Pub/Sub (MVP-Ansatz)[\[30\]][\[49\]].

Zusammengefasst: **Der Event-Bus nach dem Pub/Sub-Prinzip ist das RÃ¼ckgrat der Systemkommunikation.** Das EVENT\_SCHEMA.json stellt sicher, dass alle Services dieselbe Sprache sprechen, und in ARCHITEKTUR.md bzw. obiger Tabelle ist klar dokumentiert, welcher Dienst welche Events produziert oder konsumiert â€“ ein essenzielles Nachschlagewerk beim Neuaufsetzen, um nichts zu vergessen.

## 6\. Servicespezifikationen (Beispiele: Strategy, Risk, Signal-Writer, Execution)

In diesem Abschnitt werden exemplarisch einige zentrale Services im Detail beschrieben â€“ inklusive Konfiguration, Ablauf und wie sie dem allgemeinen Service-Template entsprechen. Jeder Service folgt dem gleichen Grundaufbau (siehe *SERVICE\_TEMPLATE.md*): ein eigenes Verzeichnis mit service.py (Hauptlogik), config.py (Konfigurationsladen von ENV), optionalen Hilfsmodulen (models.py fÃ¼r Datenklassen, etc.) und einem README[\[72\]]. Alle Services implementieren bestimmte Pflichtfunktionen: einen **HTTP-Healthcheck** (/health Endpoint), **strukturiertes Logging** (JSON-Format Logs), **Graceful Shutdown** via Signal-Handler und **Konfigurationsvalidierung** beim Start[\[73\]]. Dadurch verhalten sich die Services konsistent und sind im Betrieb leicht zu Ã¼berwachen.

**Strategie-Engine (Signal-Generator):** Dieser Service verantwortet die **Handelsstrategie**. Er liest kontinuierlich Marktdaten vom market\_data Topic (abonniert z.B. auf Kurse von BTC/USDT, ETH/USDT etc.) und berechnet definierte Regeln/Indikatoren. In der aktuellen Implementierung handelt es sich um eine einfache **Momentum-Strategie**: Es wird z.â€¯B. geprÃ¼ft, ob der Preis eines Coins in den letzten *LOOKBACK\_MIN* Minuten um mehr als einen Schwellwert X% gestiegen/gesunken ist und ob das Volumen Ã¼ber einem Minimum liegt. Ist die Bedingung erfÃ¼llt, generiert die Strategie ein entsprechendes Kauf- oder Verkaufssignal. StandardmÃ¤ÃŸig ist die **Schwelle 3%** PreisÃ¤nderung bei mindestens **100k Volumen**, was dann eine Confidence-Berechnung triggert[\[33\]][\[74\]]. Die Strategie-Engine erstellt ein Signal-Objekt (siehe Event oben) und verÃ¶ffentlicht es auf dem signals Kanal.

Konfigurierbar ist das Verhalten Ã¼ber ENV-Variablen: z.â€¯B. SIGNAL\_THRESHOLD\_PCT (Momentum-Schwelle, Default 3.0) und SIGNAL\_MIN\_VOLUME (Mindestvolumen)[\[74\]]. Diese kÃ¶nnen in der .env angepasst werden, um die Empfindlichkeit der Strategie zu steuern. Die Engine loggt ihre Aktionen, z.B. *â€œSubscribed to Topic: market\_dataâ€* und bei Start die gesetzten Parameter[\[75\]]. Sie bietet zudem HTTP-Endpoints: /health (einfacher Ok-Check), /status (Status/Statistik der Signals, z.â€¯B. Anzahl generierter Signale, letztes Signal)[\[76\]], /metrics (Prometheus-Metriken, falls integriert). Dies hilft beim Monitoring und Testing. Die Signal-Engine lÃ¤uft kontinuierlich, d.h. es gibt eine Schleife oder einen Redis-Listener, der auf neue Marktdaten reagiert, und zwischenzeitlich berechnet sie Indikatoren (z.â€¯B. alle 1 Minute).

**Risikomanager:** Der Risk-Service implementiert die **mehrlagige Risikokontrolle** des Systems. Er empfÃ¤ngt jedes Signal vom signals Topic und prÃ¼ft nacheinander alle hinterlegten Regeln, bevor eine Order zum Exchange durchgewunken wird. Die konfigurierbaren **Schwellenwerte** sind in ENV definiert (teils mit Default): MAX\_POSITION\_PCT (max. PositionsgrÃ¶ÃŸe pro Trade, default 10% des Kapitals)[\[77\]], MAX\_EXPOSURE\_PCT (max. Gesamt-Exposition, default 50%)[\[78\]], STOP\_LOSS\_PCT (Stop-Loss pro Trade, default 2%)[\[79\]], MAX\_DAILY\_DRAWDOWN\_PCT (max. Tagesverlust, default 5%)[\[79\]]. Diese Werte sollte man vor Inbetriebnahme gemÃ¤ÃŸ Risikoprofil setzen. Beim Eintreffen eines Signals durchlÃ¤uft der Risikomanager folgende Logik (Pseudocode gekÃ¼rzt aus *Risikomanagement-Logik.md*): zuerst globale Abbruchkriterien, dann trade-spezifische Limits[\[80\]][\[81\]]. In vereinfachter Form:

1. **Tagesverlust-Limit Ã¼berschritten?** Wenn ja, **alle Trades stoppen** fÃ¼r den Tag (Circuit Breaker) â€“ Signal wird verworfen, bestehende Positionen geschlossen, Alert *â€œTagesverlust-Limit Ã¼berschritten â€“ Handel gestopptâ€* wird publiziert[\[82\]][\[83\]].

2. **Anormale Marktbedingungen?** (z.â€¯B. Exchange nicht erreichbar, extreme VolatilitÃ¤t \>10% in 5min) â€“ dann **Handel pausieren**, Signal verwerfen, Alert *â€œTrading ausgesetzt wegen Marktanomalieâ€*[\[84\]].

3. **Expositions-/Positionsanzahl-Limit?** Wenn bereits zu viele offene Positionen oder zu viel Kapital im Markt, wird das neue Signal **abgelehnt** und ein entsprechender Alert geloggt[\[85\]].

4. **PositionsgrÃ¶ÃŸe \> Max?** Wenn die vorgeschlagene Order grÃ¶ÃŸer als erlaubt, wird sie **beschnitten** auf das erlaubte Maximum[\[86\]]. D.h. der Risikomanager Ã¤ndert die Quantity auf z.â€¯B. 10% des Kapitals und lÃ¤sst das angepasste Signal passieren (optional mit Warn-Alert *â€œSignalgrÃ¶ÃŸe angepasstâ€*).

5. **Sonst:** Wenn all diese Checks bestanden sind, wird das Signal **freigegeben**[\[87\]]. Der Risikomanager erzeugt dann ein **Order-Event** auf dem Bus, das alle relevanten Orderdaten enthÃ¤lt (Symbol, Side, GrÃ¶ÃŸe, evtl. Stop-Loss).

ZusÃ¤tzlich Ã¼berwacht der Risikomanager laufend geÃ¶ffnete Trades: sollte z.â€¯B. im Verlauf ein Trade einen Verlust \> Stop-Loss-PCT erreichen, wird ein Close-Event initiiert (Position sofort schlieÃŸen)[\[83\]]. Ebenso, wenn der kumulative Tagesverlust Ã¼ber das Limit steigt, greift der Circuit Breaker jederzeit â€“ nicht nur bei neuen Signalen[\[88\]]. Die Regeln sind hierarchisch priorisiert (Tagesverlust und extreme Bedingungen ganz oben)[\[89\]], sodass immer die gravierendste SchutzmaÃŸnahme zuerst greift.

Der Risikomanager loggt alle Entscheidungen. Blockierte Signale resultieren in risk\_events\-DB-EintrÃ¤gen (mit Beschreibung, z.B. *â€œExpositions-Limit erreicht â€“ Signal verworfenâ€*) und Alerts. Freigegebene Signale sieht man indirekt durch die nachfolgenden Trades. Auch dieser Service bietet HTTP-Status (z.â€¯B. Anzahl erhaltene Signale, genehmigte vs. abgelehnte Orders)[\[90\]] und Health-Check. Beim Start loggt er die gesetzten Limits (*â€œMax Position: 10.0%â€* etc.)[\[91\]], damit klar ist, mit welchen Parametern er arbeitet.

**Execution-Service:** Diese Komponente fÃ¼hrt die **OrderausfÃ¼hrung** aus. Sie wartet auf orders Events, die vom Risikomanager kommen. Bei Eintreffen entpackt sie die Orderdaten und interagiert mit der **MEXC-BÃ¶rsen API**, typischerweise Ã¼ber eine Bibliothek wie *CCXT*, welche gÃ¤ngige Methoden bereitstellt (z.â€¯B. create\_order(...)). In der aktuellen Phase war die Execution in Entwicklung; konzipiert ist, dass der Service sowohl Market-Orders als auch Limit/Stop je nach Bedarf platzieren kann. Wichtig: Die **API-Keys** mÃ¼ssen korrekt konfiguriert sein (MEXC\_API\_KEY/SECRET), und es sollte das **Testnet** oder ein beschrÃ¤nktes Konto verwendet werden, um Risiken zu minimieren.

Nach Absetzen der Order wartet der Execution-Service auf die BestÃ¤tigung von der BÃ¶rse (bzw. erhÃ¤lt Ã¼ber WebSocket oder API-RÃ¼ckmeldung den Orderstatus). Daraus generiert er dann ein **order\_result** Event: im Erfolgsfall mit Status "FILLED" und Details (gefÃ¼llte Menge, Preis)[\[92\]], im Fehlerfall mit Status "ERROR"/"REJECTED" und einer Fehlermeldung. Dieses Event publiziert er auf dem Bus, damit alle anderen Module es verarbeiten. Beispielsweise erkennt der Risikomanager daran, dass eine Position nun offen ist oder dass ein Trade fehlgeschlagen ist und loggt ggf. einen Risk-Event. Das UI wÃ¼rde den neuen Trade anzeigen oder eine Fehlermeldung visualisieren.

Der Execution-Service muss robust sein gegenÃ¼ber **NetzwerkausfÃ¤llen oder API-Errors**. Implementiert ist vorgesehen: falls keine Antwort innerhalb eines Timeouts kommt, Wiederholungsversuche (mit Backoff) zu senden[\[93\]]. Dabei hilft Idempotenz: jedem Order-Event wird vorab ein eindeutiger client\_id mitgegeben[\[94\]], sodass die Execution erkennen kann, ob ein Retry dieselbe Order betrifft und nicht doppelt ausgefÃ¼hrt werden darf. Die Execution-Komponente schreibt erfolgreiche Trades in die Datenbank (Tabelle trades) und aktualisiert ggf. positions und balances. In Compose ist sie so konfiguriert, dass sie auf Postgres wartet[\[20\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L236-L244), damit die DB-Verbindung steht. Logs des Execution-Services enthalten u.a. Order-Requests, RÃ¼ckmeldungen der BÃ¶rse und etwaige Exception-Traces bei Fehlern. Auch hier gibt es einen /health Endpoint.

**Signal-Writer / Persistenz:** In der aktuellen Architektur gibt es (noch) keinen separaten Persistenz-Container; stattdessen Ã¼bernehmen die bestehenden Services die Aufgabe, relevante Daten in die DB zu schreiben. So kann z.â€¯B. der Signal-Generator jeden generierten Signal in die signals\-Tabelle einfÃ¼gen, und der Execution-Service jeden ausgefÃ¼hrten Trade in trades. Der Risk-Manager kÃ¶nnte alle Alerts/Risk-Events in risk\_events loggen. Dieser Ansatz wurde wahrscheinlich fÃ¼r das MVP gewÃ¤hlt, um KomplexitÃ¤t zu sparen (kein separater Service nÃ¶tig). Perspektivisch ist aber ein **dedizierter Persistenz-Service** sinnvoll, wie in der Architektur vorgesehen[\[42\]]. Dieser wÃ¼rde sich auf Topics wie signals, order\_result, alerts subscriben und alle Ereignisse parallel in der DB abspeichern (als Audit-Trail). Beim Neuaufsetzen ist es wichtig zu wissen: **Datenpersistenz lÃ¤uft Ã¼ber die DB** â€“ es gibt keine andere Statefulness in den Services selbst. Wenn also die DB intakt aus einem Backup wiederhergestellt wird und die Services neu starten, haben sie den vollen Verlauf (z.â€¯B. offene Positionen kÃ¶nnen aus positions gelesen werden). Falls die DB verloren ginge, startet der Bot â€œfrischâ€ â€“ was man nur in AusnahmefÃ¤llen mÃ¶chte.

Alle Services orientieren sich am gemeinsamen **Service-Template** (einheitlicher Aufbau und Grundfunktionen)[\[73\]], was den Betrieb vereinfacht: z.â€¯B. reagiert jeder Dienst auf SIGTERM mit einem sauberen Shutdown (Connection Close, Thread Stop) gemÃ¤ÃŸ implementiertem Signal-Handler, und jeder Dienst nutzt strukturiertes Logging Ã¼ber die Python logging Bibliothek (Format im JSON-Stil). Dadurch sind Logs zentral auswertbar. Ebenso prÃ¼fen die Services bei Start die wichtigsten ENV-Variablen â€“ z.â€¯B. ob Redis-Host gesetzt, Port gÃ¼ltig, Limits sinnvoll â€“ und werfen Fehler, falls Konfigurationsfehler vorliegen[\[95\]][\[96\]]. Dies verhindert hÃ¤ufige Fehlkonfigurationen beim Deployment.

## 7\. Tests und Debugging (End-to-End Tests & Diagnose)

Nach dem Aufsetzen des Systems sollte ein **End-to-End-Test** durchgefÃ¼hrt werden, um sicherzustellen, dass alle Komponenten ordnungsgemÃ¤ÃŸ funktionieren. HierfÃ¼r liegt die Anleitung *END\_TO\_END\_TEST\_GUIDE.md* vor, die Schritt fÃ¼r Schritt das Vorgehen beschreibt. Wichtige Punkte daraus:

* **Container-Start prÃ¼fen:** ZunÃ¤chst wird via docker-compose up \-d das Gesamtsystem gestartet. Erwartet wird, dass alle definierten Container hochfahren und den Status "healthy" erreichen[\[97\]]. Konkret sollten mindestens Redis, PostgreSQL, Signal-Engine und Risk-Manager laufen (im Entwicklungsstand ggf. plus der Datenfeed cdb\_ws). In Docker Desktop kann man dies visuell kontrollieren; alternativ per docker ps.

* **Logs beobachten:** FÃ¼r jeden Service sollten die Logs keine Fehler anzeigen. Die Test-Anleitung empfiehlt, in Docker Desktop oder via docker logs \<container\> die Ausgaben zu verfolgen[\[98\]]. Typische Meldungen fÃ¼r einen erfolgreichen Start sind z.â€¯B.:

* *Signal-Engine:* â€Redis verbunden: redis:6379â€œ, â€Subscribed zu Topic: market\_dataâ€œ, â€ğŸš€ Signal-Engine gestartet (Schwelle: 3.0%)â€œ[\[75\]].

* *Risk-Manager:* â€Redis verbunden: redis:6379â€œ, â€Subscribed zu Topic: signalsâ€œ, â€ğŸš€ Risk-Manager gestartet (Max Position: 10.0% ...)â€œ[\[91\]].

* Datenfeed (cdb\_ws): Meldet Verbindung zur BÃ¶rse und dass MarketData-Events publiziert werden (z.â€¯B. Top Movers alle X Sekunden).  
  Fehlermeldungen (ERROR im Log) dÃ¼rfen **nicht** auftauchen[\[99\]]. Falls doch, mÃ¼ssen sie untersucht werden (z.â€¯B. Redis-Verbindung fehlgeschlagen, weil falsches Passwort).

* **Health-Checks:** Als NÃ¤chstes ruft man die Health-URLs der Services ab (z.â€¯B. http://localhost:8001/health fÃ¼r Signal, 8002/health fÃ¼r Risk) â€“ entweder im Browser, via Curl oder wie im Guide gezeigt mit PowerShells Invoke-WebRequest[\[100\]]. Erwartet wird jeweils ein JSON {"status":"ok", ...} mit HTTP 200[\[101\]]. Ein ausbleibendes OK deutet auf ein Service-Problem hin (dann Logs checken).

* **Redis-Events Ã¼berprÃ¼fen:** Man kann in den Redis-Container reinschauen: docker exec \-it cdb\_redis redis-cli und dort MONITOR eingeben[\[102\]]. Damit sieht man alle Pub/Sub-AktivitÃ¤ten live. Im erfolgreichen Betrieb sollte im Sekundentakt ein PUBLISH "market\_data" ... auftauchen[\[103\]] (der Datenfeed sendet kontinuierlich Marktdaten). Zudem spÃ¤testens nach einigen Momenten erste PUBLISH "signals" ... und ggf. orders wenn Signale freigegeben wurden. Das zeigt, dass die gesamte Pipeline vom Datenfeed Ã¼ber Strategie zu Risk funktioniert. AnschlieÃŸend CTRL+C in Redis CLI, um den Monitor zu verlassen.

* **Datenbankinhalte prÃ¼fen:** Mit docker exec \-it cdb\_postgres psql \-U \<USER\> \-d claire\_de\_binare kann man sich auf die DB schalten[\[104\]]. Dort lassen sich Abfragen durchfÃ¼hren, um zu sehen, ob Daten ankommen. Beispielsweise die Anzahl der Signals: SELECT COUNT(\*) FROM signals; â€“ nach ein paar Minuten Laufzeit sollte \>0 herauskommen[\[105\]]. Oder man schaut die letzten EintrÃ¤ge an (SELECT \* FROM signals ORDER BY timestamp DESC LIMIT 5;). Die Anleitung gibt hier konkrete SQL-Beispiele, etwa um die letzten 5 Signale mit Zeitstempel anzuzeigen[\[106\]], oder Risk-Events und eine Zusammenfassung aller Kernzahlen (Anzahl Signale, Risk-Events, offene Trades, Gesamtorders)[\[107\]]. Diese Queries sollten Ergebnissen liefern (z.â€¯B. einige Signale und ggf. Risk-Events, falls Limits gerissen wurden). Stimmen die Zahlen nicht (z.â€¯B. 0 Signale trotz Marktdaten), stimmt etwas im vorherigen Schritt nicht.

* **Service-Metriken:** Die Guide schlÃ¤gt ferner vor, die /status Endpoints abzufragen (sofern implementiert)[\[108\]][\[90\]]. Dort sieht man z.â€¯B. wie viele Signale generiert und wie viele Orders genehmigt/blockiert wurden â€“ ein direkter Indikator, ob die Strategie und der Risikomanager sinnvoll arbeiten. Beispielsweise kÃ¶nnte signals\_generated bei der Signal-Engine \>0 sein und orders\_approved beim Risk-Manager ebenfalls \>0 nach einiger Laufzeit[\[109\]].

Am Ende definiert der End-to-End-Test eine **Checkliste von Erfolgskriterien** (7/7 mÃ¼ssen erfÃ¼llt sein)[\[110\]]:  
1\. Alle Container laufen und sind *healthy*.  
2\. Health-Checks der Services antworten mit 200 OK.  
3\. Redis antwortet auf PING (Verbindung okay).  
4\. PostgreSQL: notwendige Rollen/Benutzer vorhanden (Setup korrekt).  
5\. PostgreSQL: Verbindung aus Container erfolgreich.  
6\. Signal-Engine: Keine Errors, Health ok.  
7\. Risk-Manager: Keine Errors, Health ok.

Wenn all das erfÃ¼llt ist, gilt der Test als bestanden[\[111\]] â€“ das System ist dann **vollstÃ¤ndig einsatzbereit** (in der Doku beispielhaft am 21.10.2025 so vermerkt).

**Troubleshooting & Debugging:** Tritt irgendwo ein Problem auf, gibt es in den Dokumenten Hilfestellungen:

* Zuallererst sollte man die Container-Logs prÃ¼fen (docker logs \<name\>), da hier meist bereits ersichtlich ist, wo es hakt (z.â€¯B. Exception wegen fehlender Umgebungsvariable oder Verbindungsfehler).

* In *CODE\_CLEANUP\_AUDIT.md* und *TROUBLESHOOTING.md* finden sich Checklisten: z.â€¯B. ob die .env\-Datei korrekt ist (keine Duplikate, alle PasswÃ¶rter konsistent)[\[112\]]. Ein docker-compose config Befehl kann Syntaxfehler in der Compose oder fehlende ENV anzeigen[\[113\]].

* HÃ¤ufige Probleme beim Start: **Redis nicht erreichbar** â€“ dann den Redis-Container (neu) starten[\[114\]]; **Port-Kollision** â€“ wenn z.â€¯B. noch ein alter Prozess auf 8001 lÃ¤uft, muss dieser beendet oder der Port geÃ¤ndert werden[\[114\]]; **fehlende ENV-Variablen** â€“ dann .env Ã¼berprÃ¼fen und korrekt befÃ¼llen[\[114\]].

* **Keine Marktdaten/Signale:** PrÃ¼fen, ob der Datenfeed lÃ¤uft (docker logs cdb\_ws) und ob dieser erfolgreich auf Redis publiziert (siehe Redis MONITOR). Gegebenenfalls sicherstellen, dass die API-Keys gÃ¼ltig sind und das Netzwerk Zugriff auf MEXC hat.

* **Keine DB-EintrÃ¤ge:** PrÃ¼fen, ob die Services DB-Verbindungsdaten haben (docker exec cdb\_signal env | grep POSTGRES beispielsweise)[\[115\]]. Fehlt hier etwas, dann .env falsch oder der Service wurde ohne DB-Anbindung gebaut. Testhalber kann man auch manuell ein Signal in Redis stellen, um die Verarbeitungskette zu stimulieren (siehe Guide: mit redis-cli ein Test-Event auf market\_data publizieren)[\[116\]].

* **Performance/Delay:** Wenn z.â€¯B. Signale generiert werden, aber Execution spÃ¤t reagiert, kÃ¶nnte die Bottleneck der Exchange API sein â€“ hier sind ggf. Ratenlimits zu beachten. Logs mit Timestamp helfen, solche Lags zu identifizieren.

Generell sollte man im Fehlerfall zunÃ¤chst die spezifischen Komponenten prÃ¼fen (oft ist es ein kleines Config-Detail). Die umfangreichen Dokumentationen (ARCHITEKTUR.md, End-to-End Guide, etc.) sind so gestaltet, dass sie fÃ¼r jedes Symptom mÃ¶gliche Ursachen bereitstellen.

## 8\. Sicherheit und Recovery (Risiken, Secrets, Backup, Rollback)

Beim Neuaufsetzen des Servers sind einige **Sicherheitsaspekte** und **Wiederanlauf-Strategien** zu beachten, um einen sicheren, nahtlosen Betrieb zu gewÃ¤hrleisten:

**Risiken beim Neuaufsetzen:**  
\- *Konfigurationsfehler:* Ein groÃŸes Risiko ist, dass ENV-Secrets falsch eingegeben werden (z.â€¯B. vertippter API-Key, falsches DB-Passwort). Dies kann dazu fÃ¼hren, dass der Bot zwar startet, aber keine Trades ausfÃ¼hrt oder keine Daten empfÃ¤ngt. LÃ¶sung: penible ÃœberprÃ¼fung der .env gegen die Doku.  
\- *Datenverlust:* Wird der Server neu aufgesetzt ohne vorheriges Backup, kÃ¶nnen alle **persistierten Signale, Trades und Parameter** verloren gehen. Dadurch gehen wichtige Referenzen fÃ¼r Risikometriken (z.â€¯B. bisheriger Tagesverlust) verloren. AuÃŸerdem wÃ¤ren Audit-Logs weg, was **Transparenz** und Nachvollziehbarkeit beeintrÃ¤chtigt. Daher immer **vor dem Neuaufsetzen Backups ziehen** (siehe unten).  
\- *Secrets-Leaks:* WÃ¤hrend des Neuaufsetzens ist darauf zu achten, dass **SchlÃ¼ssel und PasswÃ¶rter** nicht in falsche HÃ¤nde geraten. .env-Dateien sollen z.â€¯B. mittels restriktiver Dateirechte geschÃ¼tzt sein[\[4\]]. Im Idealfall liegen Secrets in einem Vault und werden zur Deployzeit injected. Kein Secret sollte im Klartext in ein Repository committet werden.  
\- *Unbeabsichtigte Withdrawals:* Sicherheitsprinzip ist â€Sicherheit vor Profitâ€œ â€“ d.h. selbst wenn der Server kompromittiert wÃ¼rde, dÃ¼rfen API-Keys keine Auszahlung erlauben[\[117\]]. Beim Neuaufsetzen stets API-SchlÃ¼ssel ohne Withdraw-Rechte verwenden[\[4\]] und ggf. IP-Whitelist bei der BÃ¶rse aktivieren. So minimiert man das finanzielle Risiko.  
\- *Ausfallrisiko:* WÃ¤hrend der Neuinstallation steht der Bot ggf. kurz still. Wenn dies wÃ¤hrend volatiler Marktphasen passiert, kÃ¶nnten Chancen verpasst werden â€“ das ist jedoch bewusst in Kauf zu nehmen gegenÃ¼ber einem unsauberen Live-Wechsel. Wichtig ist eher, dass nach Wiederanlauf **alle Komponenten synchron** laufen, um Fehlentscheidungen zu vermeiden (z.â€¯B. Risk-Manager denkt, es gibt keine offenen Positionen, obwohl an der BÃ¶rse noch welche offen sind). Hier muss man ggf. manuell verifizieren, dass beim Neustart die internen Daten (Datenbank) mit dem tatsÃ¤chlichen BÃ¶rsenstatus konsistent sind.

**Umgang mit Secrets:** Wie oben erwÃ¤hnt, sollten Secrets (API Keys, PasswÃ¶rter) **ausschlieÃŸlich Ã¼ber Environment-Variablen** oder ein Secret-Management-Tool eingespeist werden[\[4\]]. In Docker-Compose kÃ¶nnen .env-Dateien benutzt werden, was bereits implementiert ist (env\_file: .env in allen relevanten Services[\[118\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L106-L114)[\[119\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L202-L210)). Nach dem Neuaufsetzen ist zu prÃ¼fen, dass die .env-Datei korrekt vorliegt. Sie sollte **nicht** Teil von Backups in Klartext sein (laut Backup-Anleitung wird .env explizit ausgenommen[\[120\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L44-L48)). Beim Recovery also daran denken, die .env manuell zu sichern/verifizieren.

Alle Container laufen mit reduzierten Rechten (non-root) und zusÃ¤tzlichen Sicherheitsoptionen (z.â€¯B. no-new-privileges, read\_only Dateisystem in Compose)[\[121\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L216-L224)[\[122\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L246-L254). Diese Hardening-MaÃŸnahmen reduzieren die AngriffsflÃ¤che. Trotzdem sollte das System nur in vertrauenswÃ¼rdigen Netzwerken laufen und Firewalls die offenen Ports (8000-8003, 5432, 6379 etc.) absichern, vor allem wenn auf einem Cloud-Server.

**Backup-Strategie:** FÃ¼r Betriebssicherheit und schnelle Wiederherstellung ist ein regelmÃ¤ÃŸiges Backup unverzichtbar. Im Projekt gibt es eine ausfÃ¼hrliche *BACKUP\_ANLEITUNG.md*, die ein tÃ¤gliches Vollbackup vorsieht. Zusammengefasst werden **jeden Tag um 3:00 Uhr** folgende Komponenten gesichert[\[123\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L30-L38)[\[124\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L50-L58):

1. *PostgreSQL-Datenbank:* Komplettes Dump aller Tabellen (Signals, Trades, Orders, Positions, Balances, Risk-Events, Metrics, Health-Checks, Strategy-Params)[\[125\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L32-L40) â€“ so geht keine historische Trading-Information verloren.

2. *Redis-Snapshot:* Der aktuelle Redis-In-Memory-Store (der die momentanen Topics/ZustÃ¤nde hÃ¤lt) wird gesichert[\[126\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L38-L41). Dies ist zwar weniger kritisch (da nach Neustart Redis leer startet und das System trotzdem funktioniert), aber fÃ¼r Debugging oder Replay von zuletzt publizierten Events hilfreich.

3. *Projektverzeichnis:* Der gesamte Code und die Dokumentation (alles unter dem Repository, inkl. Dockerfiles, Compose, Skripte) werden archiviert[\[127\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L42-L48). Ausgenommen sind temporÃ¤re/vertrauliche Dinge wie Logs, \_\_pycache\_\_, node\_modules, .git und .env[\[120\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L44-L48). Damit ist gewÃ¤hrleistet, dass bei einem Serververlust der exakt gleiche Code wiederhergestellt werden kann â€“ wichtig, falls lokale Ã„nderungen vorgenommen wurden.

4. *Docker-Volumes:* Alle persistente Volumes der Container (Postgres-Datenfiles, Redis Dump, Prometheus TSDB, Grafana config) werden wegsichert[\[124\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L50-L58). Dies erlaubt notfalls auch eine punktgenaue Wiederherstellung des Zustands (z.â€¯B. DB-Files direkt zurÃ¼ckspielen statt nur SQL-Import).

5. *Logs:* Alle vorhandenen Logfiles werden als ZIP archiviert[\[128\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L56-L58), um im Nachhinein Fehlerursachen analysieren zu kÃ¶nnen oder ein Reporting der AktivitÃ¤ten zu haben.

Die Backup-Anleitung beschreibt, wo diese Backups liegen (z.â€¯B. unter C:\\Backups\\claire\_de\_binare\\ mit Ordnern pro Datum)[\[129\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L70-L78). Beim Neuaufsetzen **nach einem Crash** sollte man zunÃ¤chst das letzte Vollbackup einspielen:

**Recovery/Restore:** Die Schritte zur Wiederherstellung sind im Backup-Dokument skizziert[\[130\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/BACKUP_ANLEITUNG.md#L94-L100): *(1)* alle laufenden Container stoppen, *(2)* den Postgres-Dump (.sql) zurÃ¼ck in die DB importieren, *(3)* den Redis RDB-Snapshot ins neue Redis-Verzeichnis legen (optional), *(4)* die Docker-Volumes (sofern im Backup als Tar/Zip) wiederherstellen, *(5)* die Container erneut starten, und *(6)* das System ausgiebig testen. Oft reicht es aber, einfach die DB mit dem Dump zu fÃ¼llen, da darin alle wichtigen historischen Daten stecken. Redis-Inhalt kann man meist weglassen (der fÃ¼llt sich wieder). Wichtig ist, dass nach dem Recovery die **Datenkonsistenz** geprÃ¼ft wird â€“ z.â€¯B. ob offene Trades in der DB zu real existierenden Positionen an der BÃ¶rse passen. Gegebenenfalls muss man hier manuell nachjustieren (im Extremfall einen Trade schlieÃŸen, falls die Software ihn als offen fÃ¼hrt, die BÃ¶rse aber nicht â€“ oder umgekehrt).

**Rollback:** Falls ein Neuaufsetzen (z.â€¯B. mit einer neuen Version des Bots) fehlschlÃ¤gt oder Probleme bereitet, sollte man vorbereitet sein, auf den vorherigen Stand zurÃ¼ckzurollen. Dazu bewÃ¤hrt es sich, **vor dem Upgrade** ein Backup zu haben (siehe oben). Ein Rollback bestÃ¼nde dann darin, die alte Code-Version wieder zu deployen und die vor dem Upgrade gesicherten Daten zurÃ¼ckzuspielen. Dank Docker kann man auch versionierte Images nutzen: z.â€¯B. das alte Docker-Compose oder Tagged-Images der Services. Im Zweifel lÃ¤sst sich auch nur die Datenbank rÃ¼ckspielen, falls das Code-Update unproblematisch war, aber z.â€¯B. falsche Berechnungen machte â€“ so hat man den Stand vor dem Fehler wieder.

**ZusÃ¤tzliche SicherheitsmaÃŸnahmen:** GemÃ¤ÃŸ Manifest legt Claire de Binare mehr Wert auf Sicherheit als auf maximale Profitjagd[\[131\]]. Daher sind im Betrieb einige Mechanismen aktiv, die auch beim Neuaufsetzen zu berÃ¼cksichtigen sind:

* Ein **Circuit-Breaker/Not-Aus** ist integraler Bestandteil â€“ im UI gibt es einen Knopf, aber auch automatisch greift der Risk-Manager bei gefÃ¤hrlichen Situationen[\[132\]][\[133\]]. Nach einem Neustart sollte dieser Mechanismus unverÃ¤ndert aktiv sein (d.h. keine Neustart durchfÃ¼hren, um einen Crash-Loop nach Circuit-Breaker zu umgehen, ohne das Grundproblem zu lÃ¶sen). Wenn z.â€¯B. Tagesverlust Ã¼berschritten war und der Bot gestoppt wurde, sollte man bis zum nÃ¤chsten Tag warten oder die Tagesverlust-Tracking zurÃ¼cksetzen, bevor man neu startet.

* **Logs & Monitoring:** Die Sicherheit umfasst auch, dass Anomalien schnell erkannt werden. Nach Neuaufsetzen unbedingt die Logs beobachten (mindestens in den ersten Stunden Live-Betrieb) und sicherstellen, dass Monitoring-Tools wie Prometheus/Grafana laufen (im Compose enthalten)[\[134\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L53-L61)[\[135\]](https://github.com/jannekbuengener/Claire-de-Binare/blob/4ccbfbb4d2b69d8d0bdef6128dcf5c0df701a955/docker-compose.yml#L73-L81). Grafana kann Alerts definieren, die bei bestimmten Events Alarm schlagen.

* **Benutzerzugriff:** Sofern das Dashboard/UI mit Authentifizierung ausgestattet ist (z.â€¯B. 2FA, wie geplant[\[136\]]), muss beim Neuaufsetzen die User-Config Ã¼bernommen werden. Falls es keinen persistierten Userstore gibt (UI evtl. readonly mit Single-User), ist das weniger Thema.

Alles in allem ist ein Neuaufsetzen mit diesem Dokument und den vorhandenen Scripts gut machbar. Wichtig ist ein **sorgfÃ¤ltiges Vorgehen** â€“ erst die Basisdienste, dann die Bot-Services starten; vorab Secrets kontrollieren; nachher Tests ausfÃ¼hren. Die vorhandenen Backup- und Sicherheitsrichtlinien sorgen dafÃ¼r, dass auch im Fehlerfall kein groÃŸer Schaden entsteht (Daten und Geld bleiben sicher).

## 9\. Besonderheiten (ML-Modul, Shadow-Mode, essentielle Deliverables)

Zum Abschluss noch einige projektspezifische Besonderheiten, die beim Neuaufsetzen oder Betrieb bedacht werden sollten:

**ML-Modul im â€œShadow-Modeâ€:** Claire de Binare ist bislang strikt regelbasiert-deterministisch, hat aber perspektivisch ein Machine-Learning-Modul als Erweiterung vorgesehen. Dieses ML-Modul (ein *ML-basierter Signal-Advisor*) soll zunÃ¤chst in einem **Shadow Mode** laufen â€“ d.h. **parallel** zum eigentlichen Signalsystem, ohne direkt Trades auszulÃ¶sen. Konkret bedeutet das: Der ML-Service (ggf. eigener Microservice) wÃ¼rde die gleichen Marktdaten bekommen und eigene **ML-Signale** generieren, diese aber auf einen separaten Topic, z.â€¯B. ml\_signals, publizieren[\[137\]]. Der Risk-Manager oder ein Ã¼bergeordnetes Modul kÃ¶nnte diese ML-Signale zwar auswerten, aber nicht direkt ausfÃ¼hren, sondern hÃ¶chstens zur BestÃ¤tigung oder Alarmierung nutzen. So kann man die Leistung des ML-Modells beobachten, ohne das deterministische Kernsystem zu gefÃ¤hrden.

Beim Neuaufsetzen muss man beachten, dass ein ML-Modul (falls bereits integriert) **zusÃ¤tzliche Ressourcen** erfordert â€“ z.â€¯B. ein geladenes ML-Modell, mÃ¶glicherweise eine GPU oder spezielle Python-Dependencies (TensorFlow/PyTorch etc.). Diese mÃ¼ssen im Deployment-Stack berÃ¼cksichtigt sein (Docker-Image mit ML-Library, evtl. grÃ¶ÃŸeres Memory). Im aktuellen Projektstadium ist das ML-Modul laut Roadmap optional und nicht aktiv im Trading-Prozess[\[137\]]. Sollte es zum Einsatz kommen, sind auch hier Transparenz und Nachvollziehbarkeit Pflicht: Entscheidungen des ML mÃ¼ssen geloggt und erklÃ¤rbar sein. â€œShadow-Modeâ€ bedeutet auch, dass man **Metriken erhebt**, wie oft das ML-Modell zustimmt oder abweicht von der Regel-Engine, und diese Ergebnisse in Berichten dokumentiert. Es liegt ein Konzeptpapier vor, das genau diese Integration beleuchtet und Deliverables definiert (z.â€¯B. einen ausfÃ¼hrlichen Bericht mit Entscheidungsgrundlagen, Modellvergleich etc.). FÃ¼r den operativen Betrieb heiÃŸt das: Das ML-Modul darf **keine automatische Trade-Befugnis** haben, bevor nicht in solchen Berichten nachgewiesen wurde, dass es sicher und vorteilhaft ist â€“ es bleibt im read-only Modus in der Produktion, bis ein Go entschieden wird. Dies entspricht dem Leitprinzip, dass die deterministische Nachvollziehbarkeit gewahrt bleiben muss, egal wie â€œsmartâ€ das ML-Modell ist[\[138\]][\[139\]].

**Essenzielle Deliverables fÃ¼r Betriebssicherheit & Transparenz:** Ãœber die reine Codebasis hinaus lebt Claire de Binare von umfangreicher Dokumentation und Auditierbarkeit. Einige Artefakte, die fÃ¼r einen sicheren, transparenten Betrieb und eine schnelle Wiederinbetriebnahme essenziell sind:

* **ARCHITEKTUR.md:** Das Architektur-Doc ist die *Single Source of Truth* fÃ¼r das Systemdesign[\[140\]]. Beim Neuaufsetzen dient es als Referenz fÃ¼r alle Komponenten, Schnittstellen, Env-Variablen und Healthchecks. Jede Ã„nderung am System sollte hier nachvollzogen werden. Es gewÃ¤hrleistet, dass alle Teammitglieder und auch zukÃ¼nftige Maintainer schnell verstehen, wie die Teile zusammenspielen.

* **EVENT\_SCHEMA.json:** Das formale JSON-Schema der Events stellt sicher, dass Produzenten und Konsumenten dieselben Datenformate nutzen. Es erhÃ¶ht die Transparenz, weil es quasi die â€œVertrÃ¤geâ€ zwischen den Services dokumentiert. Beim Debugging kann man damit valide von invalide Events unterscheiden. Zudem unterstÃ¼tzt es die Auditierbarkeit: Man kÃ¶nnte eingehende und ausgehende Events gegen das Schema prÃ¼fen, um Fehler frÃ¼h zu erkennen.

* **Risikomanagement-Dokumentation:** Eine klare Beschreibung aller Risikoregeln (wie in *Risikomanagement-Logik.md* und ARCHITEKTUR.md) ist fÃ¼r die **Betriebssicherheit** fundamental. So ist fÃ¼r jeden Eingriff des Bots definiert, warum er erfolgt. Diese Dokumente dienen intern als Referenz und extern ggf. als Nachweis gegenÃ¼ber Dritten, dass kontrolliert und konservativ gehandelt wird. Ã„nderungen an Risikoparametern sollten hier dokumentiert werden, um Transparenz zu wahren.

* **Logging & Audit-Trails:** Das System ist so gebaut, dass **jede Entscheidung erklÃ¤rbar** ist â€“ nicht nur durch Code, sondern durch Logs[\[141\]]. Die strukturierte Speicherung von Signalen, Entscheidungen und Trades in der DB ermÃ¶glicht es, im Nachhinein jeden Trade zu begrÃ¼nden (â€wegen Signal X mit Grund Y, geprÃ¼ft gegen Limit Zâ€œ). Diese Audit-Trails sind ein deliverable in dem Sinne, dass sie jederzeit vorgezeigt werden kÃ¶nnen, um das Verhalten des Bots zu prÃ¼fen. Im Betrieb sollten regelmÃ¤ÃŸige Auswertungen der Logs/DB (z.â€¯B. wÃ¶chentliche Reports der Performance und Regel-Compliance) erfolgen, um frÃ¼hzeitig AuffÃ¤lligkeiten zu erkennen.

* **Backup- und Recovery-Prozesse:** Die oben erwÃ¤hnten Backup-Skripte und Anleitungen sind ein essenzieller Bestandteil der Betriebsdokumentation. Sie stellen sicher, dass ein **Wiederanlauf** nach AusfÃ¤llen mÃ¶glich ist, ohne Datenverlust. Das Vorhandensein getesteter Backup-Dateien und einer klaren Recovery-Doku (Schritt-fÃ¼r-Schritt) ist entscheidend, um im Ernstfall schnell reagieren zu kÃ¶nnen. Diese mÃ¼ssen gepflegt und aktuell gehalten werden (z.â€¯B. Anpassung falls neue Volumes/Services hinzukommen).

* **Testdokumentation (End-to-End Guide):** Ein weiterer wichtiger deliverable ist der vollstÃ¤ndige End-to-End-Testplan. Er gewÃ¤hrleistet, dass nach jeder Neuinstallation oder Ã„nderung das System auf Herz und Nieren geprÃ¼ft wird. FÃ¼r Betriebssicherheit ist es unerlÃ¤sslich, einen solchen Validierungsprozess zu haben â€“ er verhindert, dass ein fehlerhaft konfiguriertes System live geht.

* **Entscheidungs- und Ã„nderungsprotokolle:** Im Projekt werden Architektur-Entscheidungen (ADR) und Ã„nderungen dokumentiert (z.â€¯B. DECISION\_LOG.md, CHANGELOGs). Diese erhÃ¶hen die Transparenz fÃ¼r alle Beteiligten: Man kann nachvollziehen, warum z.â€¯B. von SQLite auf PostgreSQL gewechselt wurde, warum Telegram entfernt wurde (ADR-003) etc. Beim Neuaufsetzen kann man hier nachlesen, was aktuell gelten sollte.

AbschlieÃŸend lÃ¤sst sich sagen, dass Claire de Binare groÃŸen Wert auf **technische Eleganz, IntegritÃ¤t und Nachvollziehbarkeit** legt â€“ wie im Manifest festgehalten[\[142\]]. Beim Neuaufsetzen profitiert man davon: Eine gute Dokumentation, klar strukturierte Services und ein robustes Deployment-Setup sorgen dafÃ¼r, dass der Bot schnell wieder zum Laufen gebracht werden kann. Indem man den oben beschriebenen LeitfÃ¤den folgt, stellt man sicher, dass der **Betrieb sicher** (durch strenge Risk-Limits, keine Leaks), **transparent** (durch Dokumentation und Logging) und **wiederanlauf-fÃ¤hig** (durch Backups und klare Prozesse) bleibt â€“ selbst wenn der Server mal komplett neu aufgesetzt werden muss.

 Dockerfile
---
